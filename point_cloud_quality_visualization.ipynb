{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point Cloud Quality Visualization\n",
    "\n",
    "This notebook demonstrates how to visualize the quality metrics and results from the point cloud quality checks. It provides visualizations for:\n",
    "\n",
    "1. Overall quality distribution\n",
    "2. Quality metrics over time\n",
    "3. Common failure patterns\n",
    "4. 3D visualization of point clouds with quality issues\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('ggplot')\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Configure plot size\n",
    "plt.rcParams['figure.figsize'] = [12, 8]\n",
    "plt.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Quality Metrics Data\n",
    "\n",
    "First, let's load the quality metrics data from our Delta Live Tables pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load quality metrics data\n",
    "quality_metrics_df = spark.table(\"point_cloud_quality_metrics\").toPandas()\n",
    "\n",
    "# Display basic statistics\n",
    "print(f\"Total point clouds: {len(quality_metrics_df)}\")\n",
    "print(f\"Valid point clouds: {quality_metrics_df[quality_metrics_df['quality_score'] == 1.0].shape[0]}\")\n",
    "print(f\"Invalid point clouds: {quality_metrics_df[quality_metrics_df['quality_score'] < 1.0].shape[0]}\")\n",
    "print(f\"Average quality score: {quality_metrics_df['quality_score'].mean():.2f}\")\n",
    "\n",
    "# Display the first few rows\n",
    "quality_metrics_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Overall Quality Distribution\n",
    "\n",
    "Let's visualize the distribution of quality scores across all point clouds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create a histogram of quality scores\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(quality_metrics_df['quality_score'], bins=6, kde=True)\n",
    "plt.title('Distribution of Point Cloud Quality Scores', fontsize=16)\n",
    "plt.xlabel('Quality Score (0-1)', fontsize=14)\n",
    "plt.ylabel('Count', fontsize=14)\n",
    "plt.xticks(np.arange(0, 1.1, 0.2))\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Create a pie chart of pass/fail ratio\n",
    "pass_fail_counts = quality_metrics_df['quality_score'].apply(lambda x: 'Pass' if x == 1.0 else 'Fail').value_counts()\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.pie(pass_fail_counts, labels=pass_fail_counts.index, autopct='%1.1f%%', startangle=90, colors=['#4CAF50', '#F44336'])\n",
    "plt.title('Pass/Fail Ratio for Point Cloud Quality Checks', fontsize=16)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Quality Metrics Over Time\n",
    "\n",
    "Now, let's analyze how quality metrics have changed over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load quality history data\n",
    "quality_history_df = spark.table(\"point_cloud_quality_history\").toPandas()\n",
    "\n",
    "# Convert processing_date to datetime\n",
    "quality_history_df['processing_date'] = pd.to_datetime(quality_history_df['processing_date'])\n",
    "\n",
    "# Sort by date\n",
    "quality_history_df = quality_history_df.sort_values('processing_date')\n",
    "\n",
    "# Calculate success rates\n",
    "quality_history_df['ground_plane_success_rate'] = quality_history_df['valid_ground_plane_count'] / quality_history_df['total_point_clouds']\n",
    "quality_history_df['density_success_rate'] = quality_history_df['valid_density_count'] / quality_history_df['total_point_clouds']\n",
    "quality_history_df['noise_success_rate'] = quality_history_df['valid_noise_level_count'] / quality_history_df['total_point_clouds']\n",
    "quality_history_df['arc_success_rate'] = quality_history_df['no_arc_distortion_count'] / quality_history_df['total_point_clouds']\n",
    "quality_history_df['completeness_success_rate'] = quality_history_df['complete_point_cloud_count'] / quality_history_df['total_point_clouds']\n",
    "\n",
    "# Plot average quality score over time\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(quality_history_df['processing_date'], quality_history_df['avg_quality_score'], marker='o', linewidth=2)\n",
    "plt.title('Average Point Cloud Quality Score Over Time', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=14)\n",
    "plt.ylabel('Average Quality Score', fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.ylim(0, 1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot success rates for each quality check over time\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.plot(quality_history_df['processing_date'], quality_history_df['ground_plane_success_rate'], marker='o', label='Ground Plane Orientation')\n",
    "plt.plot(quality_history_df['processing_date'], quality_history_df['density_success_rate'], marker='s', label='Density Distribution')\n",
    "plt.plot(quality_history_df['processing_date'], quality_history_df['noise_success_rate'], marker='^', label='Noise Level')\n",
    "plt.plot(quality_history_df['processing_date'], quality_history_df['arc_success_rate'], marker='d', label='Arc Distortion')\n",
    "plt.plot(quality_history_df['processing_date'], quality_history_df['completeness_success_rate'], marker='*', label='Completeness')\n",
    "plt.title('Success Rates by Quality Check Over Time', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=14)\n",
    "plt.ylabel('Success Rate', fontsize=14)\n",
    "plt.ylim(0, 1.05)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Common Failure Patterns\n",
    "\n",
    "Let's analyze the most common failure patterns in our point clouds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load failure patterns data\n",
    "failure_patterns_df = spark.table(\"point_cloud_failure_patterns\").toPandas()\n",
    "\n",
    "# Sort by count in descending order\n",
    "failure_patterns_df = failure_patterns_df.sort_values('pattern_count', ascending=False)\n",
    "\n",
    "# Create a bar chart of failure patterns\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.barplot(x='pattern_count', y='failure_pattern', data=failure_patterns_df, palette='viridis')\n",
    "plt.title('Common Point Cloud Failure Patterns', fontsize=16)\n",
    "plt.xlabel('Count', fontsize=14)\n",
    "plt.ylabel('Failure Pattern', fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create a pie chart of failure patterns\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.pie(failure_patterns_df['pattern_count'], labels=failure_patterns_df['failure_pattern'], \n",
    "        autopct='%1.1f%%', startangle=90, shadow=True)\n",
    "plt.title('Distribution of Failure Patterns', fontsize=16)\n",
    "plt.axis('equal')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 3D Visualization of Point Clouds\n",
    "\n",
    "Now, let's visualize some example point clouds with quality issues to better understand the problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Function to parse points from JSON and create a 3D scatter plot\n",
    "def visualize_point_cloud(points_json, title):\n",
    "    import json\n",
    "    \n",
    "    # Parse points from JSON\n",
    "    points = json.loads(points_json)\n",
    "    \n",
    "    # Extract x, y, z coordinates\n",
    "    xs = [p['x'] for p in points]\n",
    "    ys = [p['y'] for p in points]\n",
    "    zs = [p['z'] for p in points]\n",
    "    \n",
    "    # Create 3D scatter plot\n",
    "    fig = go.Figure(data=[go.Scatter3d(\n",
    "        x=xs,\n",
    "        y=ys,\n",
    "        z=zs,\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=2,\n",
    "            color=zs,  # Color points by height\n",
    "            colorscale='Viridis',\n",
    "            opacity=0.8\n",
    "        )\n",
    "    )])\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        scene=dict(\n",
    "            xaxis_title='X',\n",
    "            yaxis_title='Y',\n",
    "            zaxis_title='Z',\n",
    "            aspectmode='data'  # Preserve aspect ratio\n",
    "        ),\n",
    "        width=800,\n",
    "        height=800,\n",
    "        margin=dict(l=0, r=0, b=0, t=40)\n",
    "    )\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Get example point clouds with different quality issues\n",
    "# Note: This assumes you have a table with point clouds and their quality metrics\n",
    "\n",
    "# Example with ground plane orientation issue\n",
    "ground_plane_issue = spark.table(\"invalid_point_clouds\") \\\n",
    "    .filter(\"ground_plane_valid = false\") \\\n",
    "    .limit(1) \\\n",
    "    .toPandas()\n",
    "\n",
    "if not ground_plane_issue.empty:\n",
    "    fig = visualize_point_cloud(ground_plane_issue.iloc[0]['points'], 'Point Cloud with Ground Plane Orientation Issue')\n",
    "    fig.show()\n",
    "\n",
    "# Example with noise issue\n",
    "noise_issue = spark.table(\"invalid_point_clouds\") \\\n",
    "    .filter(\"noise_level_valid = false\") \\\n",
    "    .limit(1) \\\n",
    "    .toPandas()\n",
    "\n",
    "if not noise_issue.empty:\n",
    "    fig = visualize_point_cloud(noise_issue.iloc[0]['points'], 'Point Cloud with Excessive Noise')\n",
    "    fig.show()\n",
    "\n",
    "# Example with arc distortion\n",
    "arc_issue = spark.table(\"invalid_point_clouds\") \\\n",
    "    .filter(\"no_arc_distortion = false\") \\\n",
    "    .limit(1) \\\n",
    "    .toPandas()\n",
    "\n",
    "if not arc_issue.empty:\n",
    "    fig = visualize_point_cloud(arc_issue.iloc[0]['points'], 'Point Cloud with Arc Distortion')\n",
    "    fig.show()\n",
    "\n",
    "# Example of a good point cloud for comparison\n",
    "good_example = spark.table(\"valid_point_clouds\") \\\n",
    "    .limit(1) \\\n",
    "    .toPandas()\n",
    "\n",
    "if not good_example.empty:\n",
    "    fig = visualize_point_cloud(good_example.iloc[0]['points'], 'Example of a Good Quality Point Cloud')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Correlation Between Quality Metrics\n",
    "\n",
    "Let's analyze if there are correlations between different quality metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create a correlation matrix\n",
    "quality_cols = ['ground_plane_valid', 'density_distribution_valid', 'noise_level_valid', 'no_arc_distortion', 'completeness_valid']\n",
    "corr_df = quality_metrics_df[quality_cols].astype(int).corr()\n",
    "\n",
    "# Plot correlation heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr_df, annot=True, cmap='coolwarm', vmin=-1, vmax=1, center=0, square=True, linewidths=.5)\n",
    "plt.title('Correlation Between Quality Metrics', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Quality Metrics by Capture Device or Location\n",
    "\n",
    "If your data includes information about the capture device or location, you can analyze quality metrics by these factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# This assumes your data has 'device_type' and 'location' columns\n",
    "# If not, you can skip this section or adapt it to your data\n",
    "\n",
    "# Check if these columns exist\n",
    "if 'device_type' in quality_metrics_df.columns and 'location' in quality_metrics_df.columns:\n",
    "    # Quality by device type\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    sns.boxplot(x='device_type', y='quality_score', data=quality_metrics_df)\n",
    "    plt.title('Point Cloud Quality by Device Type', fontsize=16)\n",
    "    plt.xlabel('Device Type', fontsize=14)\n",
    "    plt.ylabel('Quality Score', fontsize=14)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "    # Quality by location\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    sns.boxplot(x='location', y='quality_score', data=quality_metrics_df)\n",
    "    plt.title('Point Cloud Quality by Location', fontsize=16)\n",
    "    plt.xlabel('Location', fontsize=14)\n",
    "    plt.ylabel('Quality Score', fontsize=14)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Recommendations Based on Analysis\n",
    "\n",
    "Based on the analysis, we can provide recommendations for improving point cloud quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Calculate failure rates for each check\n",
    "failure_rates = {\n",
    "    'Ground Plane Orientation': (quality_metrics_df['ground_plane_valid'] == False).mean(),\n",
    "    'Density Distribution': (quality_metrics_df['density_distribution_valid'] == False).mean(),\n",
    "    'Noise Level': (quality_metrics_df['noise_level_valid'] == False).mean(),\n",
    "    'Arc Distortion': (quality_metrics_df['no_arc_distortion'] == False).mean(),\n",
    "    'Completeness': (quality_metrics_df['completeness_valid'] == False).mean()\n",
    "}\n",
    "\n",
    "# Sort by failure rate in descending order\n",
    "sorted_failure_rates = {k: v for k, v in sorted(failure_rates.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "# Create a bar chart of failure rates\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.bar(sorted_failure_rates.keys(), sorted_failure_rates.values(), color='#FF5722')\n",
    "plt.title('Failure Rates by Quality Check', fontsize=16)\n",
    "plt.xlabel('Quality Check', fontsize=14)\n",
    "plt.ylabel('Failure Rate', fontsize=14)\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print recommendations based on the most common issues\n",
    "print(\"Recommendations for Improving Point Cloud Quality:\")\n",
    "print(\"\\nBased on the analysis, the following areas need the most attention (in order of priority):\")\n",
    "\n",
    "for i, (check, rate) in enumerate(sorted_failure_rates.items(), 1):\n",
    "    if rate > 0.05:  # Only show recommendations for checks with >5% failure rate\n",
    "        print(f\"\\n{i}. {check} (Failure Rate: {rate:.1%})\")\n",
    "        \n",
    "        if check == 'Ground Plane Orientation':\n",
    "            print(\"   - Ensure the camera is held level during capture\")\n",
    "            print(\"   - Use a tripod or stabilizer for more consistent orientation\")\n",
    "            print(\"   - Check calibration of capture devices\")\n",
    "            \n",
    "        elif check == 'Density Distribution':\n",
    "            print(\"   - Ensure even coverage when capturing images around the object\")\n",
    "            print(\"   - Maintain consistent distance from the object during capture\")\n",
    "            print(\"   - Consider using more capture positions for complex objects\")\n",
    "            \n",
    "        elif check == 'Noise Level':\n",
    "            print(\"   - Use better lighting conditions to reduce noise\")\n",
    "            print(\"   - Ensure the camera lens is clean\")\n",
    "            print(\"   - Consider using cameras with better low-light performance\")\n",
    "            \n",
    "        elif check == 'Arc Distortion':\n",
    "            print(\"   - Ensure complete 360Â° coverage around the object\")\n",
    "            print(\"   - Maintain consistent height during capture\")\n",
    "            print(\"   - Check for calibration issues in the reconstruction software\")\n",
    "            \n",
    "        elif check == 'Completeness':\n",
    "            print(\"   - Ensure all parts of the object are captured, including top and bottom\")\n",
    "            print(\"   - Use sufficient overlap between images\")\n",
    "            print(\"   - Consider using more capture positions for complex objects\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
